Geoffrey Everest Hinton CC FRS FRSC[11] (born 6 December 1947) is a British-Canadian cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. Since 2013, he has divided his time working for Google (Google Brain) and the University of Toronto. In 2017, he co-founded and became the Chief Scientific Advisor of the Vector Institute in Toronto.[12][13]

With David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multi-layer neural networks,[14] although they were not the first to propose the approach.[15] Hinton is viewed as a leading figure in the deep learning community.[16][17][18][19][20] The dramatic image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky[21] and Ilya Sutskever for the ImageNet challenge 2012[22] was a breakthrough in the field of computer vision.[23]

Hinton received the 2018 Turing Award, together with Yoshua Bengio and Yann LeCun, for their work on deep learning.[24] They are sometimes referred to as the "Godfathers of AI" and "Godfathers of Deep Learning",[25][26] and have continued to give public talks together.[27]

Hinton was educated at King's College, Cambridge, graduating in 1970 with a Bachelor of Arts in experimental psychology.[1] He continued his study at the University of Edinburgh where he was awarded a Ph.D. in artificial intelligence in 1978 for research supervised by Christopher Longuet-Higgins.[3][28]

After his Ph.D. he worked at the University of Sussex, and (after difficulty finding funding in Britain)[29] the University of California, San Diego, and Carnegie Mellon University.[1] He was the founding director of the Gatsby Charitable Foundation Computational Neuroscience Unit at University College London,[1] and is currently[30] a professor in the computer science department at the University of Toronto. He holds a Canada Research Chair in Machine Learning, and is currently an advisor for the Learning in Machines & Brains program at the Canadian Institute for Advanced Research. Hinton taught a free online course on Neural Networks on the education platform Coursera in 2012.[31] Hinton joined Google in March 2013 when his company, DNNresearch Inc., was acquired. He is planning to "divide his time between his university research and his work at Google".[32]

Hinton's research investigates ways of using neural networks for machine learning, memory, perception and symbol processing. He has authored or co-authored over 200 peer reviewed publications.[2][33]

While Hinton was a professor at Carnegie Mellon University (1982–1987), David E. Rumelhart and Hinton and Ronald J. Williams applied the backpropagation algorithm to multi-layer neural networks. Their experiments showed that such networks can learn useful internal representations of data.[14] In an interview of 2018,[34] Hinton said that "David E. Rumelhart came up with the basic idea of backpropagation, so it's his invention." Although this work was important in popularizing backpropagation, it was not the first to suggest the approach.[15] Reverse-mode automatic differentiation, of which backpropagation is a special case, was proposed by Seppo Linnainmaa in 1970, and Paul Werbos proposed to use it to train neural networks in 1974.[15]

During the same period, Hinton co-invented Boltzmann machines with David Ackley and Terry Sejnowski.[35] His other contributions to neural network research include distributed representations, time delay neural network, mixtures of experts, Helmholtz machines and Product of Experts. In 2007 Hinton coauthored an unsupervised learning paper titled Unsupervised learning of image transformations.[36] An accessible introduction to Geoffrey Hinton's research can be found in his articles in Scientific American in September 1992 and October 1993.[37]

In October and November 2017 respectively, Hinton published two open access research papers[38][39] on the theme of capsule neural networks, which according to Hinton are "finally something that works well."[40]

Notable former PhD students and postdoctoral researchers from his group include Peter Dayan,[41] Sam Roweis,[41] Richard Zemel,[3][6] Brendan Frey,[7] Radford M. Neal,[8] Ruslan Salakhutdinov,[9] Ilya Sutskever,[10] Yann LeCun[42] and Zoubin Ghahramani.

Hinton was elected a Fellow of the Royal Society (FRS) in 1998.[11] He was the first winner of the Rumelhart Prize in 2001.[43] His certificate of election for the Royal Society reads:
Geoffrey E. Hinton is internationally distinguished for his work on artificial neural nets, especially how they can be designed to learn without the aid of a human teacher. This may well be the start of autonomous intelligent brain-like machines. He has compared effects of brain damage with effects of losses in such a net, and found striking similarities with human impairment, such as for recognition of names and losses of categorization. His work includes studies of mental imagery, and inventing puzzles for testing originality and creative intelligence. It is conceptual, mathematically sophisticated and experimental. He brings these skills together with striking effect to produce important work of great interest.[44]

In 2001, Hinton was awarded an Honorary Doctorate from the University of Edinburgh.[45] He was the 2005 recipient of the IJCAI Award for Research Excellence lifetime-achievement award.[46] He has also been awarded the 2011 Herzberg Canada Gold Medal for Science and Engineering.[47] In 2013, Hinton was awarded an Honorary Doctorate from the Université de Sherbrooke.[48]

In 2016, he was elected a foreign member of National Academy of Engineering "For contributions to the theory and practice of artificial neural networks and their application to speech recognition and computer vision".[49] He also received the 2016 IEEE/RSE Wolfson James Clerk Maxwell Award.[50]

He has won the BBVA Foundation Frontiers of Knowledge Award (2016) in the Information and Communication Technologies category "for his pioneering and highly influential work" to endow machines with the ability to learn.[51]

Together with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.[52][53][54]

In 2018, he was awarded a Companion of the Order of Canada.[55]

Hinton is the great-great-grandson both of mathematician and educator Mary Everest Boole with logician George Boole,[56] whose work eventually became one of the foundations of modern computer science, and of surgeon and author James Hinton[57] who was the father of Charles Howard Hinton. Hinton's father was Howard Hinton.[1][58] His middle name comes from another relative, George Everest.[29] He is the nephew of the economist Colin Clark.[59] He lost his first wife to ovarian cancer in 1994.[60]

Hinton moved from the U.S. to Canada in part due to disillusionment with Ronald Reagan-era politics and disapproval of military funding of artificial intelligence.[29]

Hinton has petitioned against lethal autonomous weapons. Regarding existential risk from artificial intelligence, Hinton typically declines to make predictions more than five years into the future, noting that exponential progress makes the uncertainty too great.[61] However, in an informal conversation with the AI risk researcher Nick Bostrom in November 2015, overheard by journalist Raffi Khatchadourian,[62] he is reported to have stated that he did not expect general A.I. to be achieved for decades ("no sooner than 2070"), and that, in the context of a dichotomy earlier introduced by Bostrom between people who think managing existential risk from artificial intelligence is probably hopeless versus easy enough that it will be solved automatically, Hinton "[is] in the camp that is hopeless."[62] He has stated, "I think political systems will use it to terrorize people" and has expressed his belief that agencies like the National Security Agency are already attempting to abuse similar technology.[62]

Asked by Nick Bostrom why he continues research despite his grave concerns, Hinton stated, "I could give you the usual arguments. But the truth is that the prospect of discovery is too sweet."[62]

According to the same report, Hinton does not categorically rule out human beings controlling an artificial superintelligence, but warns that "there is not a good track record of less intelligent things controlling things of greater intelligence".[62]